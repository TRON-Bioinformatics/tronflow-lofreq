params.cpus = 1
params.memory = '3g'

profiles {
  conda {
    params.enable_conda = true
    conda { createTimeout = "120 min" }
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  test {
    params.reference = "$baseDir/test_data/ucsc.hg19.minimal.fasta"
    params.intervals = "$baseDir/test_data/minimal_intervals.bed"
    timeline.enabled = false
    report.enabled = false
    trace.enabled = false
    dag.enabled = false
  }
}

// Export this variable to prevent local Python libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

cleanup = true

VERSION = '0.1.0'
DOI = 'doi'

manifest {
  name = 'TRON-Bioinformatics/tronflow-lofreq'
  author = 'Pablo Riesgo-Ferreiro'
  homePage = 'https://github.com/TRON-Bioinformatics/tronflow-lofreq'
  description = 'LoFreq pipeline'
  mainScript = 'main.nf'
  nextflowVersion = '>=19.10.0'
  version = VERSION
  doi = DOI
}
params.manifest = manifest

params.help_message = """
nextflow run tron-bioinformatics/tronflow-lofreq --help

Usage:
    nextflow run tron-bioinformatics/tronflow-lofreq -profile conda --input_files input_files --reference reference.fasta

This workflow is based on the implementation at /code/iCaM/scripts/mutect2_ID.sh

Input:
    * input_files: the path to a tab-separated values file containing in each row the sample name, tumor bam and normal bam
    The input file does not have header!
    Example input file:
    name1	tumor_bam1	normal_bam1
    name2	tumor_bam2	normal_bam2
    * reference: path to the FASTA genome reference (indexes expected *.fai)

Optional input:
    * output: the folder where to publish output
    * memory: the ammount of memory used by each job (default: 16g)
    * cpus: the number of CPUs used by each job (default: 2)

Output:
    * Final somatic calls VCF
    * Raw somatic calls VCF
    * Normal calls VCF
    * Tumor calls VCF
  """
